{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries"
      ],
      "metadata": {
        "id": "O0WZCGC4esL4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9od9UCHgz11V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN"
      ],
      "metadata": {
        "id": "k8iXTSyyWiJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, in_channels = 1, num_classes = 2):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size=(3,3),  stride = (1,1), padding = (1,1))\n",
        "    self.pool = nn.MaxPool2d(kernel_size = (2,2), stride = (2,2))\n",
        "    self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size=(3,3),  stride = (1,1), padding = (1,1))\n",
        "    self.fc1 = nn.Linear(16*12*12, 64)\n",
        "    self.fc2 = nn.Linear(64, 8)\n",
        "    self.fc3 = nn.Linear(8, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Pbna8U7fuZFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Importing"
      ],
      "metadata": {
        "id": "NDShMH7V8LqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for importing datasets\n",
        "#Folder --> file arrays --> individual images --> face detection and crop --> image array\n",
        "\n",
        "def create_img_array(data_max, usable_max, filepath, progressDisplay = False):\n",
        "  seen_files = []\n",
        "  image_path_array = os.listdir(filepath)\n",
        "  new_images_np_array = []\n",
        "  data_finished = 0\n",
        "  data_unusable = 0\n",
        "  x = 0\n",
        "\n",
        "  while (True):\n",
        "\n",
        "    if x == data_max:\n",
        "      break\n",
        "    if data_finished == usable_max:\n",
        "      break\n",
        "\n",
        "    filename = image_path_array[x].split('_20')[0]\n",
        "    if filename in seen_files:\n",
        "      x += 1\n",
        "      continue\n",
        "    seen_files.append(filename)\n",
        "    final_image = f\"{filepath}/{image_path_array[x]}\"\n",
        "\n",
        "    frame = cv2.imread(final_image)\n",
        "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "    for x_, y, w, h, in faces:\n",
        "      roi_gray = gray[y:y+h, x_:x_+w]\n",
        "      roi_color = frame[y:y+h, x_:x_+w]\n",
        "      cv2.rectangle(frame, (x_,y), (x_+w, y+h), (0, 255, 0), 2)\n",
        "      facess = faceCascade.detectMultiScale(roi_gray)\n",
        "      for (ex, ey, ew, eh) in facess:\n",
        "        face_roi = roi_color[ey: ey+eh, ex:ex + ew]\n",
        "\n",
        "    try:\n",
        "      face_roi = (cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY))\n",
        "      final_image = cv2.resize(face_roi, (48, 48))\n",
        "      new_images_np_array.append(final_image)\n",
        "      data_finished += 1\n",
        "    except:\n",
        "      if progressDisplay:\n",
        "        print(\"Data unusable\")\n",
        "        data_unusable += 1\n",
        "\n",
        "    if progressDisplay:\n",
        "      if (x + 1) % 10 == 0:\n",
        "        print(f\"{x + 1}/{data_max}\")\n",
        "  \n",
        "  print(f\"{data_finished}/{data_max} Successfully used\")\n",
        "  return new_images_np_array"
      ],
      "metadata": {
        "id": "8KIdVT9C8KWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize array range from 0 - 255 to 0 - 1\n",
        "def normalize(data_array):\n",
        "  new_array = []\n",
        "  for x in range(len(data_array)):\n",
        "      new = data_array[x].astype(\"float32\")\n",
        "      new /= 255\n",
        "      new_array.append(new)\n",
        "  return new_array"
      ],
      "metadata": {
        "id": "Y0xHinr18Q-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loser_path = #file path\n",
        "winner_path = #file path"
      ],
      "metadata": {
        "id": "QTHvzyTG8UnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of files\n",
        "import os\n",
        "loser_numof_files = 0\n",
        "for path in os.listdir(loser_path):\n",
        "    if os.path.isfile(os.path.join(loser_path, path)):\n",
        "        loser_numof_files += 1\n",
        "print('Loser1:', loser_numof_files, \"files\")\n",
        "\n",
        "winner_numof_files = 0\n",
        "for path in os.listdir(winner_path):\n",
        "    if os.path.isfile(os.path.join(winner_path, path)):\n",
        "        winner_numof_files += 1\n",
        "print('Winner1:', winner_numof_files, \"files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbk6N5Bx8WGS",
        "outputId": "097faf4d-7840-4353-d09e-091b91fada0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loser1: 1065 files\n",
            "Winner1: 1129 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create image array\n",
        "import cv2\n",
        "loser_faces = create_img_array(loser_numof_files, loser_numof_files, loser_path, progressDisplay = False)\n",
        "winner_faces = create_img_array(winner_numof_files, len(loser_faces), winner_path, progressDisplay = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz6YCtgY8Yx-",
        "outputId": "b51f77a4-e85c-40aa-d00f-052b2de455ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1006/1065 Successfully used\n",
            "1006/1129 Successfully used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize 1-256 --> 0-1\n",
        "winner_faces_normalized = normalize(winner_faces)\n",
        "loser_faces_normalized = normalize(loser_faces)"
      ],
      "metadata": {
        "id": "RuS45bA38dMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Randominzation & Organization"
      ],
      "metadata": {
        "id": "cjj2cLGPVcaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split, creating labels\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "wf,lf = winner_faces_normalized,loser_faces_normalized\n",
        "winner_labels = [1] * len(wf)\n",
        "loser_labels = [0] * len(lf)\n",
        "print(len(wf))\n",
        "print(len(lf))\n",
        "\n",
        "labels = winner_labels + loser_labels\n",
        "\n",
        "faces = np.concatenate([wf, lf], axis = 0)\n",
        "x_train, x_test, y_train, y_test = train_test_split(faces, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsnflLPp-w6X",
        "outputId": "50d2236e-81f5-4e83-d062-e04efc79e426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1006\n",
            "1006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batching\n",
        "def roundDown(n):\n",
        "    return int(\"{:.0f}\".format(n))\n",
        "    print(n)\n",
        "def batch(all_data, all_labels, batch_size):\n",
        "  num = roundDown(len(all_data)/batch_size)\n",
        "  new_data = []\n",
        "  new_labels = []\n",
        "  for x in range(num - 1):\n",
        "    temp_data = []\n",
        "    temp_list = []\n",
        "    for y in range(batch_size):\n",
        "      temp_data.append(all_data[0])\n",
        "      all_data.pop(0)\n",
        "      temp_list.append(all_labels[0])\n",
        "      all_labels.pop(0)\n",
        "    new_data.append([temp_data])\n",
        "    new_labels.append(temp_list)\n",
        "  return new_data, new_labels"
      ],
      "metadata": {
        "id": "oNuWkARv5pQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batched_train_data, batched_train_label = batch(x_train.tolist(), y_train, 64)\n",
        "batched_test_data, batched_test_label = batch(x_test.tolist(), y_test, 64)"
      ],
      "metadata": {
        "id": "tLYLKsloPfgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_data = torch.as_tensor(batched_train_data)\n",
        "train_data_label = torch.as_tensor(batched_train_label)\n",
        "print(train_data_data.shape) #Expected: torch.Size([23, 1, 64, 48, 48])\n",
        "print(train_data_label.shape) #Expected: torch.Size([23, 64])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyLRI_aiHyyp",
        "outputId": "f1ffe2cb-2e6c-4471-d176-6db30ee9a3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([23, 1, 64, 48, 48])\n",
            "torch.Size([23, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_data = torch.as_tensor(batched_test_data)\n",
        "test_data_label = torch.as_tensor(batched_test_label)\n",
        "print(test_data_data.shape) #Expected: torch.Size([7, 1, 64, 48, 48])\n",
        "print(test_data_label.shape) #Expected: torch.Size([7, 64])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3uJgjRiSPPr",
        "outputId": "d9670b00-1c70-4c99-8120-8be36cd98095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 1, 64, 48, 48])\n",
            "torch.Size([7, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Accuracy Calculation"
      ],
      "metadata": {
        "id": "_O_C9gHDXW-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(data, label, model, printing=False, matrix_data = False):\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "\n",
        "  WW = 0\n",
        "  WL = 0\n",
        "  LW = 0\n",
        "  LL = 0\n",
        "  all_answers = []\n",
        "  all_predictions = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in range(len(data)):\n",
        "      x = torch.as_tensor(data[i]).transpose(0, 1)\n",
        "      x = x.to(device = device)\n",
        "      y = label[i]\n",
        "      y = y.to(device = device)\n",
        "      \n",
        "      scores = model(x)\n",
        "      _, predictions = scores.max(1)\n",
        "      num_correct += (predictions == y).sum()\n",
        "      num_samples += predictions.size(0)\n",
        "      if (matrix_data):\n",
        "        all_answers.extend(label[i])\n",
        "        all_predictions.extend(predictions.tolist())\n",
        "    if (printing):\n",
        "      print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
        "\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  if (matrix_data):\n",
        "    for x in range(len(all_answers)):\n",
        "      if (all_answers[x] == 1 and all_predictions[x] == 1):\n",
        "        WW = WW + 1\n",
        "      if (all_answers[x] == 1 and all_predictions[x] == 0):\n",
        "        LW = LW + 1\n",
        "      if (all_answers[x] == 0 and all_predictions[x] == 1):\n",
        "        WL = WL + 1\n",
        "      if (all_answers[x] == 0 and all_predictions[x] == 0):\n",
        "        LL = LL + 1\n",
        "  if (matrix_data):\n",
        "    return float(num_correct)/float(num_samples)*100, WW, WL, LW, LL\n",
        "  else:\n",
        "    return float(num_correct)/float(num_samples)*100"
      ],
      "metadata": {
        "id": "B06c_4QWzREB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Parameters & Training"
      ],
      "metadata": {
        "id": "QOyo5SG1VmSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 500\n",
        "learning_rate = 0.0001\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "dH1kNNufmFWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constant Parameters\n",
        "num_classes = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "SBQcaO8dloKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/CNNWeights_Apr8_100E_NewD_0.001LR.torch\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQovQJICfa_X",
        "outputId": "1376d317-0601-4f23-f999-586f6b582b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = []\n",
        "weight_list = []\n",
        "max_test_acc = 0\n",
        "train_acc = 0\n",
        "epoch_val = 0\n",
        "WW_list = []\n",
        "WL_list = []\n",
        "LW_list = []\n",
        "LL_list = []\n",
        "for epoch in range(num_epochs):\n",
        "  total_loss = 0\n",
        "  for x in range(23):\n",
        "    data = torch.as_tensor(train_data_data[x]).transpose(0, 1)\n",
        "    data = data.to(device = device)\n",
        "    targets = train_data_label[x]\n",
        "    targets = targets.to(device = device)\n",
        "\n",
        "    scores = model(data)\n",
        "    loss = criterion(scores, targets)\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "  accuracy, WW, WL, LW, LL = check_accuracy(test_data_data, test_data_label, model, matrix_data = True)\n",
        "  WW_list.append(WW)\n",
        "  WL_list.append(WL)\n",
        "  LW_list.append(LW)\n",
        "  LL_list.append(LL)\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs} Loss: {total_loss:.4f} Testing Accuracy: {accuracy:.2f}%\")\n",
        "  if accuracy > max_test_acc:\n",
        "    max_test_acc = accuracy\n",
        "    train_acc = check_accuracy(train_data_data, train_data_label, model)\n",
        "    epoch_val = epoch\n",
        "  loss_list.append(total_loss)\n",
        "  weight_list.append(model.state_dict())"
      ],
      "metadata": {
        "id": "Q6-S-RIcyomV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test new model\n",
        "print(f\"Best Testing Accuracy: {max_test_acc:.2f} ({epoch_val + 1}th epoch)\")\n",
        "print(f\"Training Accuracy: {train_acc:.2f}\\n\")\n",
        "print(\"                   Actually Winners    Actually Losers\\n\"\n",
        "    + f\"Predicted Winners: {WW_list[epoch_val]}                 {WL_list[epoch_val]}\\n\"\n",
        "    + f\"Predicted Losers:  {LW_list[epoch_val]}                  {LL_list[epoch_val]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03mAU3DDXDT9",
        "outputId": "a6a05d00-a073-4bf4-9901-904d228e6349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Testing Accuracy: 68.75 (192th epoch)\n",
            "Training Accuracy: 96.60\n",
            "\n",
            "                   Actually Winners    Actually Losers\n",
            "Predicted Winners: 176                 77\n",
            "Predicted Losers:  63                  132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving Best Weights\n",
        "torch.save(weight_list[epoch_val], \"/content/drive/MyDrive/CNNWeights_Apr8_1_300E_0.001LR.torch\")"
      ],
      "metadata": {
        "id": "SYJYHpZqeN35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing Saved Model"
      ],
      "metadata": {
        "id": "RhvQzaiEYzVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test saved model\n",
        "value, WW, WL, LW, LL = check_accuracy(test_data_data, test_data_label, model, printing = True, matrix_data = True)\n",
        "print(f\"Testing Accuracy: {value}\\n\")\n",
        "print(\"                    Actually Winners    Actually Losers\\n\"\n",
        "    + f\"Predicted Winners: {WW}                  {WL}\\n\"\n",
        "    + f\"Predicted Losers:  {LW}                  {LL}\")\n",
        "\n",
        "value, WW, WL, LW, LL = check_accuracy(train_data_data, train_data_label, model, printing = True, matrix_data = True)\n",
        "print(f\"Training Accuracy: {value}\\n\")\n",
        "print(\"                    Actually Winners    Actually Losers\\n\"\n",
        "    + f\"Predicted Winners: {WW}                  {WL}\\n\"\n",
        "    + f\"Predicted Losers:  {LW}                  {LL}\")"
      ],
      "metadata": {
        "id": "FEgL7cT30Nbk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}